{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo\n",
    "from neo import *\n",
    "import pynwb\n",
    "from pynwb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# NWB File\n",
    "#############\n",
    "\n",
    "###filename = \"/home/elodie/NWB_Files/NWB_File_python_3_pynwb_101_ephys_data_bis.nwb\"\n",
    "#filename = \"/home/elodie/env_NWB_py3/my_notebook/my_first_test_neo_to_nwb.nwb\"\n",
    "#filename = \"/home/elodie/env_NWB_py3/my_notebook/my_first_test_neo_to_nwb_2.nwb\"\n",
    "###filename = \"/home/elodie/env_NWB_py3/my_notebook/my_first_test_neo_to_nwb_test_NWBIO.nwb\"\n",
    "####filename = \"/home/elodie/env_NWB_py3/my_notebook/my_first_test_neo_to_nwb_test_NWBIO_2.nwb\"\n",
    "#filename = '/home/elodie/env_NWB_py3/my_notebook/My_first_dataset.nwb'\n",
    "\n",
    "filename = '/Users/legouee/NWBwork/my_notebook/My_first_dataset.nwb'\n",
    "\n",
    "###filename = '/home/elodie/env_NWB_py3/my_notebook/my_first_test_neo_to_nwb_test_NWBIO.nwb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "io =  <pynwb.NWBHDF5IO object at 0x1183e6c10>\n",
      "pynwb.__version__ =  1.1.2\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "# Read NWB file from neoIO class\n",
    "##################################\n",
    "\n",
    "io = pynwb.NWBHDF5IO(filename, mode='r')\n",
    "print(\"io = \", io)\n",
    "print(\"pynwb.__version__ = \", pynwb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acquisition': {'signal0': {'data': {'attributes': {'conversion': 1.0,\n",
       "     'resolution': -1.0},\n",
       "    'data': <HDF5 dataset \"data\": shape (10000, 64), type \"<f8\">},\n",
       "   'starting_time': {'attributes': {'rate': 10000.0, 'unit': 'seconds'},\n",
       "    'data': 0.0},\n",
       "   'comments': 'no comments',\n",
       "   'description': 'no description',\n",
       "   'namespace': 'core',\n",
       "   'neurodata_type': 'TimeSeries',\n",
       "   'object_id': '6d56b6ff-de6d-4736-9f9b-fbdfa85a91fc'},\n",
       "  'signal1': {'data': {'attributes': {'conversion': 1.0, 'resolution': -1.0},\n",
       "    'data': <HDF5 dataset \"data\": shape (10000, 64), type \"<f8\">},\n",
       "   'starting_time': {'attributes': {'rate': 10000.0, 'unit': 'seconds'},\n",
       "    'data': 0.0},\n",
       "   'comments': 'no comments',\n",
       "   'description': 'no description',\n",
       "   'namespace': 'core',\n",
       "   'neurodata_type': 'TimeSeries',\n",
       "   'object_id': 'b36b0a10-e40f-4d18-8b21-f12a14256429'}},\n",
       " 'analysis': {},\n",
       " 'general': {},\n",
       " 'intervals': {'epochs': {'id': {'attributes': {'namespace': 'hdmf-common',\n",
       "     'neurodata_type': 'ElementIdentifiers',\n",
       "     'object_id': 'bf5fffe6-5672-4ca5-8c48-d6e7727ad3f5'},\n",
       "    'data': <HDF5 dataset \"id\": shape (3,), type \"<i8\">},\n",
       "   'start_time': {'attributes': {'description': 'Start time of epoch, in seconds',\n",
       "     'namespace': 'hdmf-common',\n",
       "     'neurodata_type': 'VectorData',\n",
       "     'object_id': 'c4450573-ac5a-476d-a65f-6d92c8076651'},\n",
       "    'data': <HDF5 dataset \"start_time\": shape (3,), type \"<f8\">},\n",
       "   'stop_time': {'attributes': {'description': 'Stop time of epoch, in seconds',\n",
       "     'namespace': 'hdmf-common',\n",
       "     'neurodata_type': 'VectorData',\n",
       "     'object_id': 'b419b4e7-40b8-4b9a-b80c-5160f729837a'},\n",
       "    'data': <HDF5 dataset \"stop_time\": shape (3,), type \"<f8\">},\n",
       "   'colnames': array([b'start_time', b'stop_time'], dtype='|S13'),\n",
       "   'description': 'experimental epochs',\n",
       "   'namespace': 'core',\n",
       "   'neurodata_type': 'TimeIntervals',\n",
       "   'object_id': '8836e5c4-b8ef-4875-ba2f-736d69a32b89'}},\n",
       " 'processing': {},\n",
       " 'stimulus': {'presentation': {}, 'templates': {}},\n",
       " 'units': {'id': {'attributes': {'namespace': 'hdmf-common',\n",
       "    'neurodata_type': 'ElementIdentifiers',\n",
       "    'object_id': '52964981-f153-4113-997d-1199833df1f8'},\n",
       "   'data': <HDF5 dataset \"id\": shape (0,), type \"<i4\">},\n",
       "  'colnames': array([], dtype=float64),\n",
       "  'description': 'Autogenerated by NWBFile',\n",
       "  'namespace': 'core',\n",
       "  'neurodata_type': 'Units',\n",
       "  'object_id': '25fdb077-993b-4172-8ca7-0887f03e71f4'},\n",
       " 'file_create_date': {'attributes': {},\n",
       "  'data': <HDF5 dataset \"file_create_date\": shape (1,), type \"|O\">},\n",
       " 'identifier': {'attributes': {}, 'data': ''},\n",
       " 'session_description': {'attributes': {}, 'data': 'My_first_dataset.nwb'},\n",
       " 'session_start_time': {'attributes': {},\n",
       "  'data': '2019-11-21T10:56:07.352424+01:00'},\n",
       " 'timestamps_reference_time': {'attributes': {},\n",
       "  'data': '2019-11-21T10:56:07.352424+01:00'},\n",
       " 'namespace': 'core',\n",
       " 'neurodata_type': 'NWBFile',\n",
       " 'nwb_version': '2.1.0',\n",
       " 'object_id': 'fc0942a0-49c1-46a9-9282-f70105f1185d'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.read_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "root pynwb.file.NWBFile at 0x4701910416\n",
       "Fields:\n",
       "  acquisition: {\n",
       "    signal0 <class 'pynwb.base.TimeSeries'>,\n",
       "    signal1 <class 'pynwb.base.TimeSeries'>\n",
       "  }\n",
       "  epochs: epochs <class 'pynwb.epoch.TimeIntervals'>\n",
       "  file_create_date: [datetime.datetime(2019, 11, 21, 10, 56, 7, 353409, tzinfo=tzoffset(None, 3600))]\n",
       "  intervals: {\n",
       "    epochs <class 'pynwb.epoch.TimeIntervals'>\n",
       "  }\n",
       "  session_description: My_first_dataset.nwb\n",
       "  session_start_time: 2019-11-21 10:56:07.352424+01:00\n",
       "  timestamps_reference_time: 2019-11-21 10:56:07.352424+01:00"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal0': {'data': {'attributes': {'conversion': 1.0, 'resolution': -1.0},\n",
       "   'data': <HDF5 dataset \"data\": shape (10000, 64), type \"<f8\">},\n",
       "  'starting_time': {'attributes': {'rate': 10000.0, 'unit': 'seconds'},\n",
       "   'data': 0.0},\n",
       "  'comments': 'no comments',\n",
       "  'description': 'no description',\n",
       "  'namespace': 'core',\n",
       "  'neurodata_type': 'TimeSeries',\n",
       "  'object_id': '6d56b6ff-de6d-4736-9f9b-fbdfa85a91fc'},\n",
       " 'signal1': {'data': {'attributes': {'conversion': 1.0, 'resolution': -1.0},\n",
       "   'data': <HDF5 dataset \"data\": shape (10000, 64), type \"<f8\">},\n",
       "  'starting_time': {'attributes': {'rate': 10000.0, 'unit': 'seconds'},\n",
       "   'data': 0.0},\n",
       "  'comments': 'no comments',\n",
       "  'description': 'no description',\n",
       "  'namespace': 'core',\n",
       "  'neurodata_type': 'TimeSeries',\n",
       "  'object_id': 'b36b0a10-e40f-4d18-8b21-f12a14256429'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.read_builder().groups['acquisition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_create_date': {'attributes': {},\n",
       "  'data': <HDF5 dataset \"file_create_date\": shape (1,), type \"|O\">},\n",
       " 'identifier': {'attributes': {}, 'data': ''},\n",
       " 'session_description': {'attributes': {}, 'data': 'My_first_dataset.nwb'},\n",
       " 'session_start_time': {'attributes': {},\n",
       "  'data': '2019-11-21T10:56:07.352424+01:00'},\n",
       " 'timestamps_reference_time': {'attributes': {},\n",
       "  'data': '2019-11-21T10:56:07.352424+01:00'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.read_builder().datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal0': signal0 pynwb.base.TimeSeries at 0x4701909968\n",
       " Fields:\n",
       "   comments: no comments\n",
       "   conversion: 1.0\n",
       "   data: <HDF5 dataset \"data\": shape (10000, 64), type \"<f8\">\n",
       "   description: no description\n",
       "   rate: 10000.0\n",
       "   resolution: -1.0\n",
       "   starting_time: 0.0\n",
       "   starting_time_unit: seconds,\n",
       " 'signal1': signal1 pynwb.base.TimeSeries at 0x4701911696\n",
       " Fields:\n",
       "   comments: no comments\n",
       "   conversion: 1.0\n",
       "   data: <HDF5 dataset \"data\": shape (10000, 64), type \"<f8\">\n",
       "   description: no description\n",
       "   rate: 10000.0\n",
       "   resolution: -1.0\n",
       "   starting_time: 0.0\n",
       "   starting_time_unit: seconds}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "io.read().acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r_ep =  epochs pynwb.epoch.TimeIntervals at 0x4701912656\n",
      "Fields:\n",
      "  colnames: ['start_time' 'stop_time']\n",
      "  columns: (\n",
      "    start_time <class 'hdmf.common.table.VectorData'>,\n",
      "    stop_time <class 'hdmf.common.table.VectorData'>\n",
      "  )\n",
      "  description: experimental epochs\n",
      "  id: id <class 'hdmf.common.table.ElementIdentifiers'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_ep = io.read().epochs\n",
    "print(\"r_ep = \", r_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"io.read().epochs.colnames = \", io.read().epochs.colnames)\n",
    "#print(\"   \")\n",
    "#print(\"io.read().epochs.fields = \", io.read().epochs.fields)\n",
    "#print(\"   \")\n",
    "#epochs_description = io.read().epochs.description\n",
    "#print(\"epochs_description = \", epochs_description)\n",
    "#print(\"   \")\n",
    "#epochs_id = io.read().epochs.id\n",
    "#print(\"epochs_id = \", epochs_id)\n",
    "#print(\"   \")\n",
    "#epochs_name = io.read().epochs.name\n",
    "#print(\"epochs_name = \", epochs_name)\n",
    "#print(\"   \")\n",
    "#epochs_columns = io.read().epochs.columns\n",
    "#print(\"epochs_columns = \", epochs_columns[0]) # start_time description\n",
    "#print(\"   \")\n",
    "#\n",
    "#print(\"   \")\n",
    "#epochs_start_time = io.read().epochs[0]\n",
    "#print(\"epochs_start_time = \", epochs_start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If several epochs\n",
    "#for j in range(len(io.read().epochs)):\n",
    "#    print(\"j = \", j)\n",
    "#    epochs_id = io.read().epochs[j][0]\n",
    "#    print(\"epochs_start_id = \", epochs_id)\n",
    "#    print(\"   \")\n",
    "#    epochs_start_time = io.read().epochs[j][1]\n",
    "#    print(\"epochs_start_time = \", epochs_start_time)\n",
    "#    print(\"   \")\n",
    "#    epochs_stop_time = io.read().epochs[j][2]\n",
    "#    print(\"epochs_stop_time = \", epochs_stop_time)\n",
    "#    print(\"   \")\n",
    "#    all_epochs = io.read().epochs[j][:]\n",
    "#    print(\"all_epochs = \", all_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_filenames =  /Users/legouee/NWBwork/my_notebook/My_first_dataset.nwb\n",
      "filenames =  /Users/legouee/NWBwork/my_notebook/My_first_dataset.nwb\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-f634dbfd9cdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filenames = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHierarchyDescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNXGraphHierarchyDescription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# Plotting settings\n",
    "show_bar_plot = False    # Change setting to plot distribution of object sizes in the HDF5 file\n",
    "plot_single_file = True # Plot all files or a single example file\n",
    "output_filenames = filename\n",
    "print(\"output_filenames = \", output_filenames)\n",
    "    \n",
    "# Select the files to plot\n",
    "filenames = output_filenames\n",
    "print(\"filenames = \", filenames)\n",
    "\n",
    "from utils.render import HierarchyDescription, NXGraphHierarchyDescription\n",
    "import matplotlib.pyplot as plt\n",
    "        \n",
    "# Create the plots for all files\n",
    "file_hierarchy = HierarchyDescription.from_hdf5(filenames)\n",
    "file_graph = NXGraphHierarchyDescription(file_hierarchy)          \n",
    "fig = file_graph.draw(show_plot=False,\n",
    "                      figsize=(12,16),\n",
    "                      label_offset=(0.0, 0.0065),\n",
    "                      label_font_size=10)\n",
    "plot_title = filenames + \" \\n \" + \"#Datasets=%i, #Attributes=%i, #Groups=%i, #Links=%i\" % (len(file_hierarchy['datasets']), len(file_hierarchy['attributes']), len(file_hierarchy['groups']), len(file_hierarchy['links']))\n",
    "plt.title(plot_title)\n",
    "plt.show()\n",
    "        \n",
    "# Show a sorted bar plot with the sizes of all datasets in the file\n",
    "if show_bar_plot:\n",
    "    d = {i['name']: np.prod(i['size']) for i in file_hierarchy['datasets']}\n",
    "    l = [w for w in sorted(d, key=d.get, reverse=True)]\n",
    "    s = [d[w] for w in l]   \n",
    "    p = np.arange(len(l))   \n",
    "    fig,ax = plt.subplots(figsize=(16,7))\n",
    "    ax.set_title(filename)\n",
    "    ax.bar(p, s, width=1, color='r')\n",
    "    ax.set_xticks(p+1)  \n",
    "    ax.set_xticklabels(l)  \n",
    "    ax.set_yscale(\"log\", nonposy='clip')\n",
    "    fig.autofmt_xdate(bottom=0.2, rotation=90, ha='right')\n",
    "    plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = file_graph.draw(show_plot=False,\n",
    "                      figsize=(12,16),\n",
    "                      label_offset=(0.0, 0.0065),\n",
    "                      label_font_size=10)\n",
    "plot_title = filenames + \" \\n \" + \"#Datasets=%i, #Attributes=%i, #Groups=%i, #Links=%i\" % (len(file_hierarchy['datasets']), len(file_hierarchy['attributes']), len(file_hierarchy['groups']), len(file_hierarchy['links']))\n",
    "plt.title(plot_title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = io.read().__nwbfields__\n",
    "print(\"fields = \", fields)\n",
    "print(\"   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.read_builder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.read().intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in io.read_builder():\n",
    "    print(\"i = \", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.read().acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
